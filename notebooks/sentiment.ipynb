{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b007c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda (NVIDIA GeForce RTX 4070 SUPER)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc63eb2426154e31a4d1450e80382df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/234 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9466, 'grad_norm': 6.3337297439575195, 'learning_rate': 1.7222222222222224e-05, 'epoch': 0.8333333333333334}\n",
      "{'eval_loss': 0.7323023080825806, 'eval_accuracy': 0.8297872340425532, 'eval_f1': 0.8312190049592065, 'eval_runtime': 0.0539, 'eval_samples_per_second': 871.457, 'eval_steps_per_second': 55.625, 'epoch': 1.0}\n",
      "{'loss': 0.7221, 'grad_norm': 5.563094139099121, 'learning_rate': 1.4722222222222224e-05, 'epoch': 1.6666666666666665}\n",
      "{'eval_loss': 0.49311476945877075, 'eval_accuracy': 0.8936170212765957, 'eval_f1': 0.8927393238703429, 'eval_runtime': 0.054, 'eval_samples_per_second': 870.184, 'eval_steps_per_second': 55.544, 'epoch': 2.0}\n",
      "{'loss': 0.4798, 'grad_norm': 3.602574586868286, 'learning_rate': 1.1944444444444444e-05, 'epoch': 2.5}\n",
      "{'eval_loss': 0.3328285813331604, 'eval_accuracy': 0.9148936170212766, 'eval_f1': 0.9139077918473215, 'eval_runtime': 0.0605, 'eval_samples_per_second': 777.437, 'eval_steps_per_second': 49.624, 'epoch': 3.0}\n",
      "{'loss': 0.3776, 'grad_norm': 4.44394063949585, 'learning_rate': 9.166666666666666e-06, 'epoch': 3.3333333333333335}\n",
      "{'eval_loss': 0.29351410269737244, 'eval_accuracy': 0.9361702127659575, 'eval_f1': 0.9358675584879392, 'eval_runtime': 0.0552, 'eval_samples_per_second': 851.797, 'eval_steps_per_second': 54.37, 'epoch': 4.0}\n",
      "{'loss': 0.3115, 'grad_norm': 4.422285556793213, 'learning_rate': 6.3888888888888885e-06, 'epoch': 4.166666666666667}\n",
      "{'loss': 0.2337, 'grad_norm': 4.0796799659729, 'learning_rate': 3.6111111111111115e-06, 'epoch': 5.0}\n",
      "{'eval_loss': 0.2557094395160675, 'eval_accuracy': 0.9361702127659575, 'eval_f1': 0.9358675584879392, 'eval_runtime': 0.0365, 'eval_samples_per_second': 1286.361, 'eval_steps_per_second': 82.108, 'epoch': 5.0}\n",
      "{'loss': 0.2156, 'grad_norm': 3.847743034362793, 'learning_rate': 8.333333333333333e-07, 'epoch': 5.833333333333333}\n",
      "{'eval_loss': 0.2513090670108795, 'eval_accuracy': 0.9361702127659575, 'eval_f1': 0.9358675584879392, 'eval_runtime': 0.0532, 'eval_samples_per_second': 882.952, 'eval_steps_per_second': 56.359, 'epoch': 6.0}\n",
      "{'train_runtime': 11.2537, 'train_samples_per_second': 99.7, 'train_steps_per_second': 6.398, 'train_loss': 0.4617964070704248, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./sentiment_model\\\\tokenizer_config.json',\n",
       " './sentiment_model\\\\special_tokens_map.json',\n",
       " './sentiment_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Silenciar warnings y configurar logs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.ERROR)\n",
    "datasets_logger = logging.getLogger(\"datasets\")\n",
    "datasets_logger.setLevel(logging.ERROR)\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "\n",
    "# Confguración para usar la GPU disponible (RTX 4070 SUPER)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo: {device} ({torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'})\")\n",
    "\n",
    "df = pd.read_csv(\"../data/mails_dataset.csv\")\n",
    "\n",
    "# Combinar asunto y cuerpo con separador especial\n",
    "df['text_combined'] = df['subject'].fillna('') + ' </s> ' + df['text'].fillna('')\n",
    "df = df[['text_combined', 'sentiment']].dropna()\n",
    "\n",
    "# Codificar categorías\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"sentiment\"])\n",
    "label2id = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Crear Dataset HuggingFace\n",
    "dataset = Dataset.from_pandas(df.rename(columns={\"text_combined\": \"text\", \"label\": \"label\"}))\n",
    "\n",
    "# Tokenizar texto\n",
    "model_name = \"pysentimiento/robertuito-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "num_labels = len(label2id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_sentiment\",\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Evaluación\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Guardar modelo y tokenizer\n",
    "trainer.save_model(\"./sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dbb3b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación por clase:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.90      1.00      0.95         9\n",
      "      neutro       0.94      0.89      0.92        19\n",
      "    positivo       0.95      0.95      0.95        19\n",
      "\n",
      "    accuracy                           0.94        47\n",
      "   macro avg       0.93      0.95      0.94        47\n",
      "weighted avg       0.94      0.94      0.94        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Obtener predicciones sobre el set de evaluación\n",
    "predictions = trainer.predict(dataset[\"test\"])\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Mostrar el reporte con los nombres reales de las clases\n",
    "print(\"Reporte de clasificación por clase:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a001615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Desktop\\MailClassifier\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asunto + Cuerpo                                                        | Esperado   | Predicción\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Pedido con retraso. Mi pedido llegó con dos días de retraso, aunque    | neutro     | neutro    \n",
      "Producto defectuoso. Recibí el producto con un defecto y quisiera u    | negativo   | negativo  \n",
      "Excelente servicio. Muy satisfecho con la rapidez y eficiencia en l    | positivo   | positivo  \n",
      "Cargos no reconocidos. He detectado cargos que no reconozco en la f    | negativo   | negativo  \n",
      "Consulta técnica. ¿El modelo X200 está disponible en negro y con ga    | neutro     | neutro    \n",
      "Agradecimiento. Agradezco mucho la asistencia que me brindaron. Tod    | positivo   | positivo  \n",
      "Pedido incompleto. El pedido llegó incompleto. Faltan artículos que    | negativo   | negativo  \n",
      "Solicitud de información. ¿Podrían enviarme los detalles técnicos d    | neutro     | neutro    \n",
      "Soporte técnico eficaz. El soporte técnico resolvió todo a la perfe    | positivo   | positivo  \n",
      "Incidencia sin resolver. Sigo esperando solución a mi problema. Est    | negativo   | negativo  \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Aciertos: 10 / 10  →  Precisión: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar modelo y tokenizer desde HuggingFace\n",
    "clf_sentiment = pipeline(\"text-classification\",model=\"aaronmena02/sentiment-model-mailclassifier\", tokenizer=\"aaronmena02/sentiment-model-mailclassifier\")\n",
    "\n",
    "# Ejemplos para pruebas\n",
    "ejemplos_sentiment = [\n",
    "    (\"Pedido con retraso\", \"Mi pedido llegó con dos días de retraso, aunque el producto está bien\", \"neutro\"),\n",
    "    (\"Producto defectuoso\", \"Recibí el producto con un defecto y quisiera un reemplazo urgente\", \"negativo\"),\n",
    "    (\"Excelente servicio\", \"Muy satisfecho con la rapidez y eficiencia en la entrega\", \"positivo\"),\n",
    "    (\"Cargos no reconocidos\", \"He detectado cargos que no reconozco en la factura. Necesito revisión\", \"negativo\"),\n",
    "    (\"Consulta técnica\", \"¿El modelo X200 está disponible en negro y con garantía extendida?\", \"neutro\"),\n",
    "    (\"Agradecimiento\", \"Agradezco mucho la asistencia que me brindaron. Todo fue excelente\", \"positivo\"),\n",
    "    (\"Pedido incompleto\", \"El pedido llegó incompleto. Faltan artículos que ya he pagado\", \"negativo\"),\n",
    "    (\"Solicitud de información\", \"¿Podrían enviarme los detalles técnicos del producto Z45, por favor?\", \"neutro\"),\n",
    "    (\"Soporte técnico eficaz\", \"El soporte técnico resolvió todo a la perfección. Muchas gracias\", \"positivo\"),\n",
    "    (\"Incidencia sin resolver\", \"Sigo esperando solución a mi problema. Esto es muy frustrante\", \"negativo\"),\n",
    "]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"{'Asunto + Cuerpo':<70} | {'Esperado':<10} | {'Predicción':<10}\")\n",
    "print(\"-\" * 115)\n",
    "aciertos = 0\n",
    "\n",
    "for asunto, cuerpo, esperado in ejemplos_sentiment:\n",
    "    texto = f\"{asunto.strip()}. {cuerpo.strip()}\"\n",
    "    pred = clf_sentiment(texto)[0]\n",
    "    print(f\"{texto[:67]:<70} | {esperado:<10} | {pred['label'].lower():<10}\")\n",
    "    if pred['label'].lower() == esperado:\n",
    "        aciertos += 1\n",
    "\n",
    "porcentaje_acierto = (aciertos / len(ejemplos_sentiment)) * 100\n",
    "print(\"-\" * 115)\n",
    "print(f\"Aciertos: {aciertos} / {len(ejemplos_sentiment)}  →  Precisión: {porcentaje_acierto:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
