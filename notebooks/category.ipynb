{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6066471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda (NVIDIA GeForce RTX 4070 SUPER)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca88e37ce3b4bcab2b90bba571a1637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2534, 'grad_norm': 6.2626519203186035, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.7692307692307693}\n",
      "{'eval_loss': 1.037034273147583, 'eval_accuracy': 0.6153846153846154, 'eval_f1': 0.616846614923538, 'eval_runtime': 0.064, 'eval_samples_per_second': 812.513, 'eval_steps_per_second': 62.501, 'epoch': 1.0}\n",
      "{'loss': 0.9465, 'grad_norm': 5.310665130615234, 'learning_rate': 1.4871794871794874e-05, 'epoch': 1.5384615384615383}\n",
      "{'eval_loss': 0.7411546111106873, 'eval_accuracy': 0.8653846153846154, 'eval_f1': 0.8591570591570592, 'eval_runtime': 0.064, 'eval_samples_per_second': 812.501, 'eval_steps_per_second': 62.5, 'epoch': 2.0}\n",
      "{'loss': 0.696, 'grad_norm': 4.509370803833008, 'learning_rate': 1.230769230769231e-05, 'epoch': 2.3076923076923075}\n",
      "{'eval_loss': 0.592818021774292, 'eval_accuracy': 0.8653846153846154, 'eval_f1': 0.8591570591570592, 'eval_runtime': 0.064, 'eval_samples_per_second': 812.529, 'eval_steps_per_second': 62.502, 'epoch': 3.0}\n",
      "{'loss': 0.58, 'grad_norm': 4.542764186859131, 'learning_rate': 9.743589743589744e-06, 'epoch': 3.076923076923077}\n",
      "{'loss': 0.4308, 'grad_norm': 4.395135879516602, 'learning_rate': 7.17948717948718e-06, 'epoch': 3.8461538461538463}\n",
      "{'eval_loss': 0.5204209685325623, 'eval_accuracy': 0.8653846153846154, 'eval_f1': 0.8591570591570592, 'eval_runtime': 0.062, 'eval_samples_per_second': 838.716, 'eval_steps_per_second': 64.517, 'epoch': 4.0}\n",
      "{'loss': 0.3364, 'grad_norm': 4.147921562194824, 'learning_rate': 4.615384615384616e-06, 'epoch': 4.615384615384615}\n",
      "{'eval_loss': 0.48972612619400024, 'eval_accuracy': 0.8653846153846154, 'eval_f1': 0.8591570591570592, 'eval_runtime': 0.066, 'eval_samples_per_second': 787.879, 'eval_steps_per_second': 60.606, 'epoch': 5.0}\n",
      "{'train_runtime': 10.0982, 'train_samples_per_second': 121.21, 'train_steps_per_second': 7.724, 'train_loss': 0.6790378570556641, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./category_model\\\\tokenizer_config.json',\n",
       " './category_model\\\\special_tokens_map.json',\n",
       " './category_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Silenciar warnings y configurar logs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.ERROR)\n",
    "datasets_logger = logging.getLogger(\"datasets\")\n",
    "datasets_logger.setLevel(logging.ERROR)\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "\n",
    "#Confguración para usar la GPU disponible (RTX 4070 SUPER)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo: {device} ({torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'})\")\n",
    "\n",
    "df = pd.read_csv(\"../data/mails_dataset.csv\")\n",
    "\n",
    "# Combinar asunto y cuerpo con separador especial\n",
    "df['text_combined'] = df['subject'].fillna('') + ' </s> ' + df['text'].fillna('')\n",
    "df = df[['text_combined', 'category']].dropna()\n",
    "\n",
    "# Codificar categorías\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"category\"])\n",
    "label2id = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Crear Dataset HuggingFace\n",
    "dataset = Dataset.from_pandas(df.rename(columns={\"text_combined\": \"text\", \"label\": \"label\"}))\n",
    "\n",
    "# Tokenizar texto\n",
    "model_name = \"pysentimiento/robertuito-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "num_labels = len(label2id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "#Entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./category_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_category\",\n",
    "    logging_steps=10,\n",
    "    fp16=True,  \n",
    "    report_to=\"none\" \n",
    ")\n",
    "\n",
    "#Evaluación\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "#Guardar modelo y tokenizer\n",
    "trainer.save_model(\"./category_model\")\n",
    "tokenizer.save_pretrained(\"./category_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0bb299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación por clase:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   comercial       1.00      0.88      0.93         8\n",
      "        otro       0.89      0.62      0.73        13\n",
      "       queja       0.85      1.00      0.92        17\n",
      "   solicitud       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.87        52\n",
      "   macro avg       0.89      0.85      0.86        52\n",
      "weighted avg       0.87      0.87      0.86        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Obtener predicciones sobre el set de evaluación\n",
    "predictions = trainer.predict(dataset[\"test\"])\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Mostrar el reporte con los nombres reales de las clases\n",
    "print(\"Reporte de clasificación por clase:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0447ed9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asunto + Cuerpo                                                        | Esperado   | Predicción\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Reclamo por pedido no entregado. Mi pedido no ha llegado y ya pasar    | queja      | queja     \n",
      "Consulta sobre disponibilidad. ¿Pueden confirmarme si tienen stock     | solicitud  | solicitud \n",
      "Interés en cotización empresarial. Solicito información detallada p    | comercial  | solicitud \n",
      "Agradecimiento. Gracias por la atención, todo perfecto                 | otro       | otro      \n",
      "Número de seguimiento. Solicito el número de seguimiento del pedido    | solicitud  | solicitud \n",
      "Producto dañado. Recibí el producto roto y nadie contesta              | queja      | queja     \n",
      "Descuentos para distribuidores. ¿Ofrecen descuentos para distribuid    | comercial  | comercial \n",
      "Todo correcto. Todo ha ido perfecto, gracias                           | otro       | otro      \n",
      "Agendar llamada de negocios. Estariamos encantados de agendar una l    | comercial  | comercial \n",
      "Garantía. ¿Me podrían confirmar si el producto tiene garantía?         | solicitud  | solicitud \n",
      "No funciona el artículo recibido. El equipo llegó pero no enciende.    | queja      | queja     \n",
      "Solicitud de factura. Necesito la factura del pedido número 78492      | solicitud  | solicitud \n",
      "Reunión de colaboración. Nos gustaría organizar una reunión para ex    | comercial  | solicitud \n",
      "Agradecimiento por soporte. Gracias por resolver tan rápido el prob    | otro       | otro      \n",
      "Problemas con la app. No puedo iniciar sesión desde ayer. ¿Pueden a    | queja      | queja     \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Aciertos: 13 / 15  →  Precisión: 86.67%\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar modelo y tokenizer desde Hugging Face\n",
    "clf = pipeline(\"text-classification\", model=\"aaronmena02/category-model-mailclassifier\", tokenizer=\"aaronmena02/category-model-mailclassifier\")\n",
    "\n",
    "#Ejemplos para pruebas\n",
    "ejemplos = [\n",
    "    (\"Reclamo por pedido no entregado\", \"Mi pedido no ha llegado y ya pasaron 10 días\", \"queja\"),\n",
    "    (\"Consulta sobre disponibilidad\", \"¿Pueden confirmarme si tienen stock del producto?\", \"solicitud\"),\n",
    "    (\"Interés en cotización empresarial\", \"Solicito información detallada para contratar su servicio\", \"comercial\"),\n",
    "    (\"Agradecimiento\", \"Gracias por la atención, todo perfecto\", \"otro\"),\n",
    "    (\"Número de seguimiento\", \"Solicito el número de seguimiento del pedido\", \"solicitud\"),\n",
    "    (\"Producto dañado\", \"Recibí el producto roto y nadie contesta\", \"queja\"),\n",
    "    (\"Descuentos para distribuidores\", \"¿Ofrecen descuentos para distribuidores?\", \"comercial\"),\n",
    "    (\"Todo correcto\", \"Todo ha ido perfecto, gracias\", \"otro\"),\n",
    "    (\"Agendar llamada de negocios\", \"Estariamos encantados de agendar una llamada para hablar de una propuesta que puede interesarles\", \"comercial\"),\n",
    "    (\"Garantía\", \"¿Me podrían confirmar si el producto tiene garantía?\", \"solicitud\"),\n",
    "    (\"No funciona el artículo recibido\", \"El equipo llegó pero no enciende. Espero respuesta.\", \"queja\"),\n",
    "    (\"Solicitud de factura\", \"Necesito la factura del pedido número 78492\", \"solicitud\"),\n",
    "    (\"Reunión de colaboración\", \"Nos gustaría organizar una reunión para explorar posibles colaboraciones de cara a futuro\", \"comercial\"),\n",
    "    (\"Agradecimiento por soporte\", \"Gracias por resolver tan rápido el problema\", \"otro\"),\n",
    "    (\"Problemas con la app\", \"No puedo iniciar sesión desde ayer. ¿Pueden ayudarme?\", \"queja\"),\n",
    "]\n",
    "\n",
    "# Calcular y mostrar porcentaje de aciertos\n",
    "print(f\"{'Asunto + Cuerpo':<70} | {'Esperado':<10} | {'Predicción':<10}\")\n",
    "print(\"-\" * 115)\n",
    "aciertos = 0\n",
    "for asunto, cuerpo, esperado in ejemplos:\n",
    "    texto = f\"{asunto.strip()}. {cuerpo.strip()}\"\n",
    "    pred = clf(texto)[0]\n",
    "    print(f\"{texto[:67]:<70} | {esperado:<10} | {pred['label']:<10}\")\n",
    "    \n",
    "    if pred['label'] == esperado:\n",
    "        aciertos += 1\n",
    "\n",
    "porcentaje_acierto = (aciertos / len(ejemplos)) * 100\n",
    "print(\"-\" * 115)\n",
    "print(f\"Aciertos: {aciertos} / {len(ejemplos)}  →  Precisión: {porcentaje_acierto:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
